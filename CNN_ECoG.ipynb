{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import scipy\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_snips(data_file, im_len, stride_len):\n",
    "    '''takes the matlab file for a patient and creates images of the ecog data for training/testing. We have a 2D array made up of \n",
    "    electrode voltage vs time. This single, long signal needs to chopped up into smaller peices to create the desired dataset of 'images'\n",
    "    args:\n",
    "        data_file: matlab file for a patient\n",
    "        i_len (int): length of each image (in ms)\n",
    "        stride_len (int): length of stride (in ms)\n",
    "    returns: \n",
    "        image_data (list): list of (image, label) pairs. image (2D array) -->electrode num voltages vs time, label (2D array) --> joystick coordinates vs time '''\n",
    "    data = scipy.io.loadmat(data_file)\n",
    "    array = data['data'].astype(np.float32)\n",
    "    \n",
    "#     # filter ecog\n",
    "#     lowcut = 0.15\n",
    "#     highcut = 200\n",
    "#     order = 4\n",
    "#     nyquistFreq = 1000 \n",
    "#     # The Nyquist frequency is the highest frequency that equipment of a given sample rate can reliably measure, \n",
    "#     # one-half the given sample rate.\n",
    "\n",
    "#     low  = lowcut / nyquistFreq\n",
    "#     high = highcut / nyquistFreq\n",
    "\n",
    "#     b, a = scipy.signal.butter(order, [low, high], btype='bandpass')\n",
    "#     ch_num = array.shape[1]\n",
    "#     array = np.zeros_like(array)\n",
    "#     for i in range(ch_num):\n",
    "#         array[:,i] = scipy.signal.filtfilt(b, a, array[:, i]) \n",
    "    \n",
    "    \n",
    "    indices = [(i, i+im_len) for i in list(range(0, array.shape[0] - im_len +1, stride_len))]\n",
    "    cut_signals = [array[i[0]:i[1], :] for i in indices]\n",
    "    assert len(data['CursorPosX']) == len(data['CursorPosY'])\n",
    "    l_max = max(np.max(data['CursorPosX']), np.max(data['CursorPosY']))\n",
    "    t_sample = [i+im_len-1 for i in list(range(0, len(data['CursorPosX']) - im_len +1, stride_len))]\n",
    "    \n",
    "    trajectory = [[data['CursorPosX'][i,0].astype(np.float16)/l_max, data['CursorPosY'][i,0].astype(np.float16)/l_max] for i in t_sample]\n",
    "    # cut_signals.shape = (num_images, im_len, num_electrodes)\n",
    "    return [(cut_signals[i].T, trajectory[i]) for i in range(len(cut_signals))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dataDir = r'/Users/yiting/Documents/NMA_DL/Project/Movement_BCI/joystick_track/data'\n",
    "files = os.listdir(dataDir)\n",
    "# load the data for the first patient\n",
    "data= scipy.io.loadmat(os.path.join(dataDir, files[0]))\n",
    "path_orange = r'/Users/yiting/Documents/NMA_DL/Project/Movement_BCI/joystick_track/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, num_electrodes, im_len):\n",
    "        super(EEGNet, self).__init__()\n",
    "        # Layer 1\n",
    "        self.K1 = 16 #num of kernels\n",
    "        self.K1_size = (num_electrodes, 1) #size of kernels\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=self.K1, kernel_size=self.K1_size, padding = 0) #K1 kernels in the first layer, \n",
    "                                                            # each being Cx1 [1d convolution that combines the channel activity across all times into one number]\n",
    "        self.batchnorm1 = nn.BatchNorm2d(self.K1, False)\n",
    "        \n",
    "        # Layer 2\n",
    "        self.pad2_x = [0, 0]\n",
    "        self.pad2_y = [0, 0]\n",
    "        #kernels for layer 2\n",
    "        self.K2 = 4\n",
    "        self.K2_size = (3, 3)\n",
    "        self.padding1 = nn.ZeroPad2d((self.pad2_x[0], self.pad2_x[1], self.pad2_y[0], self.pad2_y[1]))\n",
    "        self.conv2 = nn.Conv2d(1, self.K2, self.K2_size)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(self.K2, False)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 4)\n",
    "        \n",
    "        # Layer 3\n",
    "        self.pad3_x = [0, 0]\n",
    "        self.pad3_y = [0, 0]\n",
    "        #kernels for layer 2\n",
    "        self.K3 = 4\n",
    "        self.K3_size = (2, 2)\n",
    "\n",
    "        self.padding2 = nn.ZeroPad2d((self.pad3_x[0], self.pad3_x[1], self.pad3_y[0], self.pad3_y[1]))\n",
    "        self.conv3 = nn.Conv2d(self.K2, self.K3, self.K3_size)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(self.K3, False)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 4))\n",
    "        self.final_layer_size = 0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        def forward_conv(self, x):\n",
    "            # print('shape before forward pass', x.shape)\n",
    "            # Layer 1\n",
    "            x = F.elu(self.conv1(x))\n",
    "            x = self.batchnorm1(x)\n",
    "            x = F.dropout(x, 0.5)\n",
    "            x = x.permute(0, 2, 1, 3)\n",
    "            # Layer 2\n",
    "            x = self.padding1(x)\n",
    "            x = F.elu(self.conv2(x))\n",
    "            x = self.batchnorm2(x)\n",
    "            x = F.dropout(x, 0.5)\n",
    "            x = self.pooling2(x)\n",
    "            \n",
    "            # Layer 3\n",
    "            x = self.padding2(x)\n",
    "            x = F.elu(self.conv3(x))\n",
    "            x = self.batchnorm3(x)\n",
    "            x = F.dropout(x, 0.5)\n",
    "            x = self.pooling3(x)\n",
    "            return x\n",
    "            #need to compute the dimension of the input of the FC layer\n",
    "        # FC Layer\n",
    "        # NOTE: This dimension will depend on the number of timestamps per sample in your data\n",
    "        x = forward_conv(self, x)\n",
    "        if self.final_layer_size == 0:\n",
    "            self.final_layer_size = torch.numel(forward_conv(self, torch.zeros(1, 1, num_electrodes, im_len)))\n",
    "            self.fc1 = nn.Linear(self.final_layer_size, 2)\n",
    "        x = x.reshape(-1, self.final_layer_size)\n",
    "        x = F.relu(self.fc1(x))\n",
    "#         x = F.sigmoid(self.fc1(x))\n",
    "        return x    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # Load or initialize your data\n",
    "        self.data = [snip[0] for snip in snipped_data] # This could be a list of images, texts, etc.\n",
    "        self.labels = [snip[1] for snip in snipped_data] # Only for supervised tasks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]  # Only for supervised tasks\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#screen refresh rate ~ 20Htz. So stride > 50ms.\n",
    "im_len = 1000\n",
    "stride_len = 100\n",
    "snipped_data = create_snips(os.path.join(dataDir, files[0]), im_len, stride_len)\n",
    "\n",
    "dataset = CustomDataset()\n",
    "#create testing and training sets:\n",
    "per_train = 0.8 #percent of data to use for training\n",
    "train_size = int(per_train * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "num_electrodes = len(snipped_data[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "net = EEGNet(num_electrodes, im_len).cpu()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "# epoch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch - 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch - 1\n",
      "\n",
      "Epoch - 2\n",
      "\n",
      "Epoch - 3\n",
      "\n",
      "Epoch - 4\n",
      "\n",
      "Epoch - 5\n",
      "\n",
      "Epoch - 6\n",
      "\n",
      "Epoch - 7\n",
      "\n",
      "Epoch - 8\n",
      "\n",
      "Epoch - 9\n"
     ]
    }
   ],
   "source": [
    "def eval(data, net, criterion):\n",
    "    #computes the forward pass and loss of the loaded_data\n",
    "    inputs = data[0]\n",
    "    labels = data[1]  # Unpack the inputs and labels from the data loader\n",
    "    l = torch.cat((labels[0], labels[1]))\n",
    "    l = l.reshape(len(labels[0]), 2)\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(inputs.unsqueeze(1))\n",
    "    #training loss\n",
    "    loss = criterion(outputs, l)\n",
    "    return loss\n",
    "train_loss_all = []\n",
    "test_loss_all = []\n",
    "for epoch in range(10):\n",
    "    print(\"\\nEpoch -\", epoch)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    train_loss_epoch = []\n",
    "    test_loss_epoch = []\n",
    "#     print('num batches', len(train_loader))\n",
    "    for i, data in enumerate(train_loader, 0):  # Use the train_loader for data loading\n",
    "        optimizer.zero_grad()\n",
    "#         print(type(data))\n",
    "        train_loss = eval(data, net, criterion)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += train_loss.item()  # Use loss.item() to get the scalar value of the loss\n",
    "\n",
    "        #test loss\n",
    "        test_loss = 0.0\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "            test_loss += eval(data, net, criterion).item()\n",
    "        test_loss /= len(test_loader)\n",
    "#         print('Batch number: ', i, 'train_Loss:', train_loss.item(), 'test_Loss:', test_loss)\n",
    "        train_loss_epoch.append(train_loss.item())\n",
    "        test_loss_epoch.append(test_loss)\n",
    "#     print(\"Epoch {} - Loss: {:.4f}\".format(epoch, running_loss))\n",
    "    train_loss_all.append(np.mean(train_loss_epoch))\n",
    "    test_loss_all.append(np.mean(test_loss_epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib import rc,rcParams\n",
    "# rc('text', usetex=True)\n",
    "# rc('font', weight='bold')\n",
    "# custom_preamble = {\n",
    "#     \"text.latex.preamble\":\n",
    "#         r\"\\usepackage{amsmath,amssymb}\" # for the align, center,... environment\n",
    "#         ,\n",
    "#     }\n",
    "# plt.rcParams.update(custom_preamble)\n",
    "#select n consecutive images and plot the actual and predicted trajectories:\n",
    "n = 100\n",
    "start = 15\n",
    "def eval_plot(data, net):\n",
    "    with torch.no_grad():\n",
    "        #computes the forward pass and loss of the loaded_data\n",
    "        inputs = torch.Tensor(data[0])  # Unpack the inputs and labels from the data loader\n",
    "        # print(inputs, labels)\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs.unsqueeze(0).unsqueeze(0))\n",
    "    return outputs[0].numpy()\n",
    "\n",
    "selected_data = snipped_data[start:start+n]\n",
    "predicted_labels = [eval_plot(data, net) for data in selected_data]\n",
    "actual_labels = [data[1] for data in selected_data]\n",
    "diff = [np.linalg.norm(predicted_labels[i] - actual_labels[i]) for i in range(len(predicted_labels))]\n",
    "print(\"Average difference between predicted and actual labels: \", np.mean(diff))\n",
    "fig, ax = plt.subplots(dpi=300)\n",
    "ms = 4\n",
    "ax.plot([predicted_labels[i][0] for i in range(len(predicted_labels))],[predicted_labels[i][1] for i in range(len(predicted_labels))], label=\"predicted\", color=\"red\",lw=0.7, marker='o', markersize=ms)\n",
    "ax.plot([actual_labels[i][0] for i in range(len(actual_labels))],[actual_labels[i][1] for i in range(len(actual_labels))], label=\"actual\", color=\"blue\",lw=0.7, marker='x', markersize=ms)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_xlim(0,1)\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_title(\"Predicted vs Actual Trajectory\")\n",
    "ax.legend()\n",
    "plt.show()\n",
    "diff = [np.linalg.norm(predicted_labels[i] - actual_labels[i]) for i in range(len(predicted_labels))]\n",
    "precentages = len(np.where(np.array(diff) < 0.1)[0])/len(diff)\n",
    "print(precentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_fc1 = net.fc1.weight\n",
    "weight_max = torch.max(weight_fc1)\n",
    "print(weight_max)\n",
    "weight_min = torch.min(weight_fc1)\n",
    "print(weight_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('/Users/yiting/Documents/NMA_DL/Project/Movement_BCI/CNN_fp_relu.png', dpi = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of EEGNet\n",
    "num_electrodes = 60\n",
    "im_len = 1000\n",
    "model = EEGNet(num_electrodes, im_len)\n",
    "\n",
    "# Calculate the total number of tunable parameters\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total number of tunable parameters:\", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 128\n",
    "# train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "# net = EEGNet(num_electrodes, im_len).cpu()\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(net.parameters())\n",
    "# epoch_size = 50\n",
    "# epoch_loss = []\n",
    "# n_batches = len(train_loader)\n",
    "# for epoch in range(epoch_size):\n",
    "#     print(\"\\nEpoch -\", epoch)\n",
    "    \n",
    "#     running_loss = 0.0\n",
    "#     for i, data in enumerate(train_loader, 0):  # Use the train_loader for data loading\n",
    "        \n",
    "#         inputs, labels = data  # Unpack the inputs and labels from the data loader\n",
    "#         # inputs = [input for input in inputs]\n",
    "#         # labels = [label for label in labels]\n",
    "#         # print('shape of the batch_inputs', inputs.shape)\n",
    "#         # wrap them in Variable (not necessary in recent versions of PyTorch)\n",
    "#         # inputs, labels = Variable(inputs.cuda(0)), Variable(labels.cuda(0))\n",
    "\n",
    "#         # zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "#         l = torch.cat((labels[0], labels[1]))\n",
    "#         l = l.reshape(len(labels[0]), 2)\n",
    "#         # forward + backward + optimize\n",
    "#         outputs = net(inputs.unsqueeze(1))\n",
    "        \n",
    "#         loss = criterion(outputs, l)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item()  # Use loss.item() to get the scalar value of the loss\n",
    "# #         # correlation\n",
    "# #         x_data = torch.cat((outputs[:,0],l[:,0]))\n",
    "# #         x_data = x_data.reshape(2,len(outputs[:,0]))\n",
    "# #         corr_x = torch.corrcoef(x_data)\n",
    "# #         y_data = torch.cat((outputs[:,1],l[:,1]))\n",
    "# #         y_data = y_data.reshape(2,len(outputs[:,1]))\n",
    "# #         corr_y = torch.corrcoef(y_data)\n",
    "\n",
    "# #         print('Batch number: ', i, 'Loss: ', loss.item())\n",
    "# #         print('Pearsons correlation for x: %.3f' % corr_x[0,1])\n",
    "# #         print('Pearsons correlation for y: %.3f' % corr_y[0,1])\n",
    "        \n",
    "# #         print('Batch number: ', i, 'Loss: ', loss.item())\n",
    "#     print(\"Epoch {} - Loss: {:.4f}\".format(epoch, running_loss / n_batches))\n",
    "#     epoch_loss.append(running_loss / n_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = [np.linalg.norm(predicted_labels[i] - actual_labels[i]) for i in range(len(predicted_labels))]\n",
    "precentages = len(np.where(np.array(diff) < 0.1)[0])/len(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(train_loss_all, label=\"train\", color=\"blue\")\n",
    "ax.plot(test_loss_all, label=\"test\", color=\"red\")\n",
    "ax.set_xlabel('Epoch Number')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend()\n",
    "\n",
    "fig.savefig('/Users/yiting/Documents/NMA_DL/Project/Movement_BCI/CNN_loss_relu.png', dpi = 150)\n",
    "# calculate accuracy\n",
    "# activation function: 0 to 1 (since we normalized the location and the values should be frmo 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), '/Users/yiting/Documents/NMA_DL/Project/Movement_BCI/EEGNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model, X, Y, params = [\"acc\"]):\n",
    "#     results = []\n",
    "#     batch_size = 128\n",
    "    \n",
    "#     predicted = []\n",
    "    \n",
    "#     for i in range(len(X)/batch_size):\n",
    "#         s = i*batch_size\n",
    "#         e = i*batch_size+batch_size\n",
    "        \n",
    "#         inputs = Variable(torch.from_numpy(X[s:e]).cuda(0))\n",
    "#         pred = model(inputs)\n",
    "        \n",
    "#         predicted.append(pred.data.cpu().numpy())\n",
    "        \n",
    "        \n",
    "#     inputs = Variable(torch.from_numpy(X).cuda(0))\n",
    "#     predicted = model(inputs)\n",
    "    \n",
    "#     predicted = predicted.data.cpu().numpy()\n",
    "    \n",
    "#     for param in params:\n",
    "#         if param == 'acc':\n",
    "#             results.append(accuracy_score(Y, np.round(predicted)))\n",
    "#         if param == \"auc\":\n",
    "#             results.append(roc_auc_score(Y, predicted))\n",
    "#         if param == \"recall\":\n",
    "#             results.append(recall_score(Y, np.round(predicted)))\n",
    "#         if param == \"precision\":\n",
    "#             results.append(precision_score(Y, np.round(predicted)))\n",
    "#         if param == \"fmeasure\":\n",
    "#             precision = precision_score(Y, np.round(predicted))\n",
    "#             recall = recall_score(Y, np.round(predicted))\n",
    "#             results.append(2*precision*recall/ (precision+recall))\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
